{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87dc1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 11:38:52.169100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Layer, ReLU, LeakyReLU\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9734bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import load_model, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c1b69",
   "metadata": {},
   "source": [
    "Restructuring data with type classification using one_hot interpretation. Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a179d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './BKG_dataset.h5'\n",
    "# make sure input data has correct input shape - background training data\n",
    "with h5py.File(filename, 'r') as file:\n",
    "    X_train = np.array(file['X_train'])\n",
    "    X_test = np.array(file['X_test'])\n",
    "    X_val = np.array(file['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e924227c",
   "metadata": {},
   "source": [
    "Define Dense NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47772fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "### Categorical data to be converted to numeric data\n",
    "colors = [\"None\", \"MET\", \"electron\", \"muon\", \"jet\"]\n",
    "\n",
    "### Universal list of colors\n",
    "total_colors = [\"None\", \"MET\", \"electron\", \"muon\", \"jet\"]\n",
    "\n",
    "### map each color to an integer\n",
    "mapping = {}\n",
    "for x in range(len(total_colors)):\n",
    "  mapping[total_colors[x]] = x\n",
    "\n",
    "# integer representation\n",
    "for x in range(len(colors)):\n",
    "  colors[x] = mapping[colors[x]]\n",
    "\n",
    "one_hot_encode = to_categorical(colors)\n",
    "print(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd21e6",
   "metadata": {},
   "source": [
    "Restructure data where object types as one_hot vector. Shape from [19,4] to [19,8] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8070c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.0988121   0.         -1.21966612 46.22872162 -1.52670538  1.81053424\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])#orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb825f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_file= '/home/aadi/praktika/ADC/files/background_for_training.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea143893",
   "metadata": {},
   "outputs": [],
   "source": [
    "events=100# mitme eventi peal treenida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "897d304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read BACKGROUND data\n",
    "with h5py.File(bkg_file, 'r') as file:\n",
    "    full_data = file['Particles'][:,:,:]\n",
    "    np.random.shuffle(full_data)\n",
    "    if events: full_data = full_data[:events,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86df65c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128684/2086445373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevent_obj_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#type of elements extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testing' is not defined"
     ]
    }
   ],
   "source": [
    "event_obj_type=testing[:,3]#type of elements extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24169055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0006a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "### Categorical data to be converted to numeric data\n",
    "colors = [\"None\", \"MET\", \"electron\", \"muon\", \"jet\"]\n",
    "\n",
    "### Universal list of colors\n",
    "total_colors = [\"None\", \"MET\", \"electron\", \"muon\", \"jet\"]\n",
    "\n",
    "### map each color to an integer\n",
    "mapping = {}\n",
    "for x in range(len(total_colors)):\n",
    "  mapping[total_colors[x]] = x\n",
    "\n",
    "# integer representation\n",
    "for x in range(len(colors)):\n",
    "  colors[x] = mapping[colors[x]]\n",
    "\n",
    "one_hot_encode = to_categorical(colors)\n",
    "print(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c0dda",
   "metadata": {},
   "source": [
    "Restructure data where object types as one_hot vector. Shape from [19,4] to [19,8] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c928b975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.04098511,  0.        , -1.0397166 ,  1.        ],\n",
       "       [31.74472618, -1.58234549,  2.9478004 ,  2.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [35.29406738, -1.50310445,  1.97888601,  4.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[3] #original 19,4 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb57e2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.64394569  0.          2.64225101  1.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [40.06128311 -0.72923177 -0.72488439  3.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [17.47454453 -2.05241919  1.47250724  4.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "testing=full_data[99]\n",
    "print(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63774d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 3. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "event_obj_type=testing[:,3]#type of elements extracted\n",
    "#np.transpose(data_obj_type)\n",
    "print(event_obj_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36885003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to onehot vector\n",
    "event_obj_oh=to_categorical(event_obj_type,5)\n",
    "#print(event_obj_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f46ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_wo_type=testing[:,:3]#event without type\n",
    "#print(event_wo_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13adebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 8)\n"
     ]
    }
   ],
   "source": [
    "event_oh=np.concatenate((event_wo_type,event_obj_oh),axis=1)\n",
    "print(event_oh.shape)\n",
    "#print(event_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0443de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suurema batchi peal\n",
    "#print(full_data[:])\n",
    "event_obj_type=full_data[:,:,3]\n",
    "#print(event_obj_type)Object types from all events\n",
    "event_obj_oh=to_categorical(event_obj_type,5)\n",
    "#print(event_obj_oh[3])All the object types turned to one hot\n",
    "event_wo_type=full_data[:,:,:3]#original events without type\n",
    "event_oh=np.concatenate((event_wo_type[:],event_obj_oh[:]),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7313dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.64394569  0.          2.64225101  0.          1.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [40.06128311 -0.72923177 -0.72488439  0.          0.          0.\n",
      "   1.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [17.47454453 -2.05241919  1.47250724  0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(event_oh[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def create_datasets_dense_onehot(bkg_file, output_bkg_name, signals_files, output_signal_names, events=None, test_size=0.2, val_size=0.2, input_shape=152):\n",
    "\n",
    "    # read BACKGROUND data\n",
    "    with h5py.File(bkg_file, 'r') as file:\n",
    "        full_data = file['Particles'][:,:,:]\n",
    "        np.random.shuffle(full_data)\n",
    "        if events: full_data = full_data[:events,:,:]\n",
    "\n",
    "    event_obj_type=full_data[:,:,3]#Object types from all events\n",
    "    event_obj_oh=to_categorical(event_obj_type,5)#All the object types turned to one hot\n",
    "    event_wo_type=full_data[:,:,:3]#original events without type\n",
    "    full_data=np.concatenate((event_wo_type[:],event_obj_oh[:]),axis=2)#original data combined with one hot vectors\n",
    "\n",
    "\n",
    "    # define training, test and validation datasets\n",
    "    X_train, X_test = train_test_split(full_data, test_size=test_size, shuffle=True)\n",
    "    X_train, X_val = train_test_split(X_train, test_size=val_size)\n",
    "\n",
    "    del full_data\n",
    "\n",
    "    # flatten the data for model input\n",
    "    X_train = X_train.reshape(X_train.shape[0], input_shape)\n",
    "    X_test = X_test.reshape(X_test.shape[0], input_shape)\n",
    "    X_val = X_val.reshape(X_val.shape[0], input_shape)\n",
    "\n",
    "\n",
    "    with h5py.File(output_bkg_name + '_OH_dataset.h5', 'w') as h5f:\n",
    "        print(\"saving\")\n",
    "        h5f.create_dataset('X_train', data = X_train)\n",
    "        h5f.create_dataset('X_test', data = X_test)\n",
    "        h5f.create_dataset('X_val', data = X_val)  \n",
    "        \n",
    "        \n",
    "    if signals_files:\n",
    "        # read SIGNAL data\n",
    "        for i, signal_file in enumerate(signals_files):\n",
    "            print(\"teen if\")\n",
    "            f = h5py.File(signal_file,'r')\n",
    "            signal_data = f['Particles'][:,:,:]\n",
    "            #same process as before turning types to onehot vectors\n",
    "            event_obj_type=signal_data[:,:,3]#Object types from all events\n",
    "            event_obj_oh=to_categorical(event_obj_type,5)#All the object types turned to one hot\n",
    "            event_wo_type=signal_data[:,:,:3]#original events without type\n",
    "            signal_data=np.concatenate((event_wo_type[:],event_obj_oh[:]),axis=2)#original data combined with one hot vectors\n",
    "            \n",
    "            signal_data = signal_data.reshape(signal_data.shape[0],input_shape)\n",
    "            with h5py.File(output_signal_names[i] + '_OH_dataset.h5', 'w') as h5f2:\n",
    "                h5f2.create_dataset('Data', data = signal_data)        \n",
    "    return                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sspython3 create_datasets_OH.py \n",
    "--bkg_file '/home/aadi/praktika/ADC/files/background_for_training.h5' \n",
    "--output_bkg_name 'BKG_OH'\n",
    "--signals_files '/home/aadi/praktika/ADC/files/Ato4l_lepFilter_13TeV.h5' \n",
    "--output_signal_names 'Ato4l_lepFilter_13TeV_OH' \n",
    "--events=1000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9da5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_files = ['/home/aadi/praktika/ADC/files/Ato4l_lepFilter_13TeV.h5',\n",
    "            '/home/aadi/praktika/ADC/files/hChToTauNu_13TeV_PU20.h5',\n",
    "            '/home/aadi/praktika/ADC/files/hToTauTau_13TeV_PU20.h5',\n",
    "            '/home/aadi/praktika/ADC/files/leptoquark_LOWMASS_lepFilter_13TeV.h5',\n",
    "            '/home/aadi/praktika/ADC/files/background_for_training.h5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2b6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_output=['Ato4l_lepFilter_13TeV_input',\n",
    "                 'hChToTauNu_13TeV_PU20_input',\n",
    "                 'hToTauTau_13TeV_PU20_input',\n",
    "                 'leptoquark_LOWMASS_lepFilter_13TeV_input',\n",
    "                 'background_for_training_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e9b5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_file= '/home/aadi/praktika/ADC/files/background_for_training.h5' \n",
    "output_bkg_name= 'BKG_OH2'\n",
    "signals_files= signal_files \n",
    "output_signal_names= signal_output\n",
    "events=4000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "589ed0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "teen if\n",
      "teen if\n",
      "teen if\n",
      "teen if\n",
      "teen if\n"
     ]
    }
   ],
   "source": [
    "create_datasets_dense_onehot(bkg_file, output_bkg_name, signals_files, output_signal_names, events=None, test_size=0.2, val_size=0.2, input_shape=152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed2d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
